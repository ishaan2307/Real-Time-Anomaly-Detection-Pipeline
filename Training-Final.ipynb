{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1887dc82-be62-4728-8349-d701d68d96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# üìÇ Load dataset\n",
    "df = pd.read_csv(\"final_injected_anomalies.csv\")\n",
    "\n",
    "# üßπ Drop unnecessary columns\n",
    "df.drop(columns=[\"Timestamp\"], inplace=True)\n",
    "\n",
    "# üß™ Select only Temperature as feature\n",
    "X = df[[\"Temperature\"]]\n",
    "y = df[\"Anomaly\"]\n",
    "\n",
    "# ‚öñÔ∏è Standardize the temperature feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# üß™ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7dd10f9-ffa0-4509-85c1-e757d99ce28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Optimized)\n",
      "Accuracy: 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2675\n",
      "           1       0.94      0.88      0.91      2725\n",
      "\n",
      "    accuracy                           0.92      5400\n",
      "   macro avg       0.92      0.92      0.91      5400\n",
      "weighted avg       0.92      0.92      0.91      5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# üîÅ Logistic Regression with polynomial features and balanced class weights\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', C=0.5, solver='liblinear'))\n",
    "])\n",
    "logistic_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# üß† Predict\n",
    "y_pred = logistic_pipeline.predict(X_test)\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"Logistic Regression (Optimized)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1178ea96-ac9b-4493-81a7-04674a495a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.9107407407407407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      2675\n",
      "           1       0.91      0.91      0.91      2725\n",
      "\n",
      "    accuracy                           0.91      5400\n",
      "   macro avg       0.91      0.91      0.91      5400\n",
      "weighted avg       0.91      0.91      0.91      5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# üîÅ Train model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# üß† Predict\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"Random Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164177c3-11ea-4554-a5cb-e49c046003f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Accuracy: 0.9303703703703704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      2675\n",
      "           1       0.92      0.94      0.93      2725\n",
      "\n",
      "    accuracy                           0.93      5400\n",
      "   macro avg       0.93      0.93      0.93      5400\n",
      "weighted avg       0.93      0.93      0.93      5400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SEM7\\SIT332\\python\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ‚öñÔ∏è Handle imbalance in anomaly data\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# üîÅ Train model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", scale_pos_weight=scale_pos_weight)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# üß† Predict\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"XGBoost\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33d75952-90b7-4ec3-981d-6ccd349f10ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest (Optimized)\n",
      "Accuracy: 0.7124074074074074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      2675\n",
      "           1       0.87      0.51      0.64      2725\n",
      "\n",
      "    accuracy                           0.71      5400\n",
      "   macro avg       0.76      0.71      0.70      5400\n",
      "weighted avg       0.76      0.71      0.70      5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# üîÅ Train with scaling and optimized parameters\n",
    "iso_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    IsolationForest(n_estimators=250, contamination=0.3, max_samples='auto', random_state=42)\n",
    ")\n",
    "iso_pipeline.fit(X_train)\n",
    "\n",
    "# üß† Predict\n",
    "y_pred = iso_pipeline.predict(X_test)\n",
    "y_pred = [1 if p == -1 else 0 for p in y_pred]\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"Isolation Forest (Optimized)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce59298a-83c9-4e54-9623-e141dff91c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Class SVM (Optimized)\n",
      "Accuracy: 0.6464814814814814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66      2675\n",
      "           1       0.66      0.61      0.64      2725\n",
      "\n",
      "    accuracy                           0.65      5400\n",
      "   macro avg       0.65      0.65      0.65      5400\n",
      "weighted avg       0.65      0.65      0.65      5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# üîÅ Train model with scaling and improved hyperparameters\n",
    "ocsvm_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    OneClassSVM(nu=0.4, kernel=\"rbf\", gamma=\"scale\")\n",
    ")\n",
    "ocsvm_pipeline.fit(X_train)\n",
    "\n",
    "# üß† Predict\n",
    "y_pred = ocsvm_pipeline.predict(X_test)\n",
    "y_pred = [1 if p == -1 else 0 for p in y_pred]  # -1 = anomaly ‚Üí 1\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"One-Class SVM (Optimized)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f3e68c6-f5e7-4b79-81d6-d78113f25540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All temperature-only models saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"saved_models_temperature_only\", exist_ok=True)\n",
    "\n",
    "# Save scaler and models\n",
    "joblib.dump(scaler, \"saved_models_temperature_only/scaler.pkl\")\n",
    "joblib.dump(logistic_pipeline, \"saved_models_temperature_only/logistic_regression.pkl\")\n",
    "joblib.dump(rf_model, \"saved_models_temperature_only/random_forest.pkl\")\n",
    "joblib.dump(xgb_model, \"saved_models_temperature_only/xgboost.pkl\")\n",
    "joblib.dump(iso_pipeline, \"saved_models_temperature_only/isolation_forest.pkl\")\n",
    "joblib.dump(ocsvm_pipeline, \"saved_models_temperature_only/one_class_svm.pkl\")\n",
    "\n",
    "print(\"‚úÖ All temperature-only models saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed05685-b9d9-4a4d-9fed-39afd175241c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
